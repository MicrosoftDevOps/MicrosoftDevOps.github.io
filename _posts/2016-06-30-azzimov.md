---
layout: post
title:  "Learnings from a DevOps Hackfest with Azzimov"
author: "Julien Stroheker & William Buchwalter"
author-link: "#"
#author-image: "{{ site.baseurl }}/images/authors/photo.jpg"
date:   2016-06-30
categories: DevOps
color: "blue"
#image: "{{ site.baseurl }}/images/azzimov1.jpg" #should be ~350px tall
excerpt: This article is aimed a sharing the learnings from a DevOps Hackfest with Azzimov.
---

## Learning from Hackfest with *Azzimov* ##

Azzimov teamed up with Microsoft during a few days to implement DevOps practices into their processes. We will describe in this report the steps we have taken and their results.

Among other things we talked about:  

* Unit Testing  
* Continuous Integration with Jenkins  
* Continuous Deployment  
* Integration Testing  

The core hacking team was composed of:  

* Kevork Aghazarian - Project Manager   
* Yassine Zeroual - System Administrator  
* Prasad Perera - Backend Developer  
* Yanick Plamondon - Backend Developer  
* Julien Stroekher ([@Ju_Stroh](https://twitter.com/Ju_Stroh)) - Technical Evangelist at Microsoft  
* William Buchwalter ([@wbuchw](https://twitter.com/wbuchw)) - Technical Evangelist at Microsoft  

## Customer Profile ##
Azzimov is a startup based in Montreal, Canada, which delivers a virtual shopping mall solution leveraging machine learning.
The main focus of this hackfest was to increase the quality and the reliability of the product and its deployments.

## Problem Statement ##

Azzimov is a very agile organization, this is why they have been able to bring innovative solutions to the market consistently for multiple years.
Keeping the same pace of delivery becomes harder as the company grows. A lot of organizations do not realize that and hire new people regularly  to counter the productivity loss, creating even more technical debt on the long run.
The other, better solution, is too invest time into managing and reducing the technical debt early and continuously. 

That is the approach Azzimov chose. The team put the emphasis on two aspects:  

* Quality: Minimizing issues and down-time in production when releasing new features.
* Time to Market: Increasing even more their ability to ship fast and stay ahead of their market. 

### Current Architecture ###

![Architecture overview](/images/AzzimovArchi.jpg)

Azzimov's architecutre is very granular with each component being isolated. This is a very good practice that makes changing any one of the components much easier (and that was great for our hackfest).
It would also greatly simplify moving to a container based architecture, but that's for another day.

For the purpose of this hackfest, we decided to hack on their most complicated component: **Trinity Gateway**.
If we managed to do something meaningful there, then Azzimov's team was confident they could implement similar practices for their other components.

Trinity Gateway is a Java based service that acts as an orchestrator for every other services of the solution.

## Solutions, Steps, and Delivery ##

The first day was dedicated to do a Value Stream Mapping. This process allows to quickly capture the waste and issues in the workflow from ideation to production.

![Value Stream Mapping](/images/AzzimovVSM.jpg)

This exercise allowed us to quickly see areas of improvements. 
  
First, we saw that there werenâ€™t enough quality checks in place to reach the level of quality that Azzimov wants.

We also found that the mean lead time from the planning of a feature to its release in production is around 5 weeks. This lead time was probably somewhat optimistic, but not too far from the truth.

Ultimately, the goal of DevOps is to reduce this lead time as much as possible to allow rapid feedback and iteration, but in order to do that, we need a way to be confident in the quality of our product.

For these reasons we decided to focus on continuous integration and continous deployment of new changes into a staging environment first. Should this be done properly, this would allow to catch any issues much faster than today, and most importantly, to spot them before they impact a customer.
This are the basic building blocs of DevOps that can be built upon later on.

Because Azzimov's team already had some experience with Jenkins, we decided to go ahead and use it.
Because we love automation, and we don't want to setup anything manually, we deployed a new Jenkins instance on Azure using an [ARM template](https://github.com/Azure/azure-quickstart-templates/tree/master/jenkins-on-ubuntu) that can be parametrized to setup any number of nodes.

Once Jenkins setup, we split the work between two teams: 
  * One team would work on continuous integration
  * The other would work on automating deployment on a staging environment

### Continuous Integration

One of the main pain that we identified during the Value Stream Mapping was the lack of tooling that could  help Azzimov to implement some DevOps practices.

From the build to the release, there was a lot of manual steps. The build (using Maven 2) was also executed manually from a developer machine. While a very common practice, by automating much of this steps, we can reduce significantly their lead time and improve quality.

We explored the concept of *Continuous Integration* and the possibility to build the code at each commit in their GitHub repository, as well as the impact of adding units testing and running them at build time.

We decided to automated those tasks and created a Pipeline project in Jenkins 2.0 that is made of the following four stages:

* **Checkout Sources** : Classic git clone of the repository
* **Build** : Building the .Jar file with Maven.
* **Unit tests** : Run a shell command to execute the JUnit tests in the project
* **Publish Artifacts** : Upload the .Jar file in an Azure Blog Storage, ready to be deployed

Here is the code of this pipeline in Jenkins :

  {% highlight groovy %}
  node {
    ws('/var/lib/jenkins/workspace/trinity') {
      // Get the maven tool.
      def mvnHome = '/usr/share/maven'

      stage 'Checkout Sources'
        git branch: 'feature/jenkin_integration', credentialsId: 'XXXXX', url: 'https://github.com/XXXXX/YYYYY'

      stage 'Build'
        sh "${mvnHome}/bin/mvn clean install -DskipTests"

      stage 'Unit Tests'
        sh "${mvnHome}/bin/mvn test"
        step([$class: 'JUnitResultArchiver', testResults: '**/target/surefire-reports/TEST-*.xml'])

      //publish the war file to azure, so it can be used later to setup a new VM  
      stage 'Publish Artifacts'
        sh "azure storage blob upload -q -a \"azziartifacts\" -k \"XXXX" \"target/SearchGateway.war\" \"trinity\""
    }
  {% endhighlight %}

The next step was to deploy this artifact (.jar) automatically in a new environment to run the integration tests.

### Continuous Deployment to staging

The idea was to automatically deploy the artifact previously built in an environment, ready to be tested. For this step, we introduced the concepts of Infrastructure as Code and Configuration Management on Microsoft Azure with  Azzimov's team.

First, we had to define the needs for the application :

* An ubuntu environment
* Java Development Kit installed (JDK)
* Tomcat binaries
* Download the artifact from the Azure Blob Storage
* Lunch Tomcat on the port 8080 with the Jar file

With an ARM template, we automatized the deployment of one Virtual Machine running Ubuntu on Azure. When this deployment was done, we added a custom extension written on Shell to run our custom settings.

One interesting countermeasure that we had to find, was the way to automatically accept the License Agreement from Java :

![Pipeline Jenkins](/images/AzzimovJavaPrompt.png)

We used the '**echo debconf**' command to remediate to it (See the next snippet)

Here is a piece of code of the shell script that we push as a custom extension in the VM :

{% highlight shell %}
sudo add-apt-repository -y ppa:webupd8team/java
sudo apt-get -y update
echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections
echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections
sudo apt-get -y install oracle-java7-installer
sudo apt-get -y install oracle-java7-set-default
{% endhighlight %}

So now that we have one json file containing our Infrastructure as code part and one shell script containing our configuration part we are ready to execute it every time that we want.

Here are the related Jenkins steps:

* **Checkout ARM Template** : Git clone of the repository containing the ARM template and shell script
* **Upload Deployment Script**  : Upload the shell file in an Azure Blog Storage, ready to be executed as a custom extension
* **Creating Resource Group** : Execute an Azure CLI command to create a resource group on Azure where we will deploy our environment
* **Deploy integration env** : Execute an Azure CLI command to deploy our environment thank to our ARM template
* **Installing trinity** : Add a custom extension on the virtual machine previously created to execute our shell script
* **Send SMS** : Send a text message to one of the OPS people to acknowledge the deployment using [Trello's](www.trello.com) API

Here is what it looks like as code:

{% highlight groovy %}
   ws('/var/lib/jenkins/workspace/trinity-deploy') {
    stage 'Checkout ARM Templates'
      git credentialsId: 'xxxx', url: 'https://github.com/xxxx/xxxx.git'

    stage 'Upload Deployment Script'
      sh "azure storage blob upload -q -a \"azziartifacts\" -k \"XXXX\" \"./scripts/deploy_gw.sh\" \"trinity\" "
      sh "azure storage blob upload -q -a \"azziartifacts\" -k \"XXXX\" \"./scripts/installTrinityExtension.sh\" \"trinity\" "

    stage 'Creating the resource group'
      sh "azure group create -n TrinityIntegration -l \"Canada East\""

    stage 'Deploy Integration env'
      sh "azure group deployment create -f azuredeploy.json -e azuredeploy.parameters.integration.json -g TrinityIntegration -n DeploymentTrinityInt"

    stage 'Installing Trinity'
      sh "/usr/bin/sudo /bin/sh ./scripts/installTrinityExtension.sh"

    stage 'Send SMS'
      sh "/usr/bin/sudo /bin/sh ./scripts/sendsms.sh"
   }
   {% endhighlight %}

### Functional testing
We then decided to push ahead with our objective of improving quality.
One of the issue is that the existing code base has not enough unit tests. As any developer will tell you, adding unit test to an existing code base that was written by someone else is a very hard task. If the codebase is somewhat large this can be a huge time investment.

While it is probably always worth going back and adding unit test to critical pieces of the application, functional tests will offer a better return on investment on the short term. By testing the whole stack, we can quickly make sure everything is working as expected before a release with minimal efforts.  

During the Value Stream Mapping we identified that the team did some manual sanity checks using curl before going into production.
We decided to create a new repository containing functional tests for all the different services, and capture the manual tests as a first step.

We decided to use Node.js for functional testing for multiple reasons:
  * Easy to pick up, and some developer already have experience with it.
  * With a library such as [mocha](https://mochajs.org/) we can easily export test results in an xUnit format to display them in Jenkins
  * Libraries such as [phantomjs](http://phantomjs.org/) will make UI testing easier on a build agent.

Here is an example of what this new tests look like:

{% highlight javascript %}
require('isomorphic-fetch');
var expect = require('expect');

describe('Connection tests', function() {
this.timeout(5000);  
  it('Initiate Session and Test MySQl connection', function(done) {
    fetch('http://someinternalurl.com:8080/')
      .then(res => res.json())
      .then(res => {
        expect(res.status).toEqual(1);
        done();
      })
      .catch(err => done(err));    
  })
});
{% endhighlight %}

We then hooked this tests into the Jenkinsfile so that they are executed once the environment finishes deploying.

{% highlight groovy %}
ws('/var/lib/jenkins/workspace/trinity-tests') {
    stage 'Checkout Functional Tests'
      git branch: 'master', url: 'https://github.com/xxxx/xxxx'

    stage 'Install dependencies'
      sh 'npm i'

    stage 'Gateway Tests'
      sh 'npm run gateway'

    stage 'Mall Tests'
      sh 'npm run mall'

    stage 'Archiving Test Results'
      //This step archive the xml file containing testresults to display them in jenkins UI
      step([$class: 'JUnitResultArchiver', testResults: '*.xml'])
  }
{% endhighlight %}

## Conclusion ##
While we can only do so much in 3 days, continuous integration, the addition of critical unit tests, and automated integration tests should already make a difference in the stability of the application when releasing a new update.
In the mean time, continuous deployment will help reduce the lead time by letting developers verify their changes more often, thus detecting issues before they reach production.  

Jenkins 2.0 new pipeline feature has proved very flexible and easy to use. Since everything is code, maintaining and evolving continuous integration and continuous deployment pipelines is straightforward.

Here is the stage view of our completed Jenkins pipeline:

![Pipeline Jenkins](/images/AzzimovPipeline.jpg)

A lot of improvement can be made to this script, among which:  

* Using Jenkins variable to detect the current branch, and deploy in production (or staging) when on `master`  
* Deploy a temporary environment on Azure for every commit using the ARM templates, run the functional tests on this envrionment and automatically deprovision it.   

## Resources ##  

* [Jenkins's Pipeline tutorial on GitHub](https://github.com/jenkinsci/pipeline-plugin/blob/master/TUTORIAL.md)
